{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# noaa-weather-hourly\n",
    "This script cleans and formats a manually downloaded National Oceanic and Atmospheric Administration (NOAA) Local Climatological Data (LCD) CSV weather file.  \n",
    "\n",
    "This is the jupyter notebook development version of the script.  This script is converted to a .py file in the final published version.\n",
    "\n",
    " __Originated From:__\n",
    "https://github.com/emskiphoto/Process-historical-NOAA-LCD-weather<BR>\n",
    "    \n",
    "Copyright Matt Chmielewski<BR>\n",
    "https://github.com/emskiphoto/noaa-weather-hourly<BR>\n",
    "January 6, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct the jupyter notebook development script to add package path to PYTHONPATH\n",
    "# to allow for loading of source modules.\n",
    "import sys\n",
    "sys.path.append('../noaa_weather_hourly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules specific to this package \n",
    "from config import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pathlib\n",
    "import re\n",
    "# turn off Jedi autocomplete (that was causing more problems than benefits post Win10 update 3-13-2020)\n",
    "%config Completer.use_jedi = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters - Store in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn on development mode to enable visualizations and other intermittent\n",
    "# quality checks that aren't avaiable in the final version\n",
    "is_development = True\n",
    "# is_development = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line Arguments\n",
    "Which arguments can be provided in the command line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 'H')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename, freqstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqstr = '30T'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/user/OneDrive/python_envs/noaa-weather-hourly-cli/dev')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_cwd = pathlib.Path.cwd()\n",
    "dir_cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using 'data' within 'dev' folder - potentially different from 'data' in package folder\n",
    "# dir_data should be dir_cwd in production script\n",
    "if is_development:\n",
    "    dir_data = dir_cwd / 'data'\n",
    "else:\n",
    "    dir_data = dir_cwd\n",
    "assert dir_data.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are there any .CSV files of any naming format?\n",
    "If not, stop the script, there is nothing to do without the local .csv's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty name of directory\n",
    "dir_data_posix = dir_data.as_posix()\n",
    "# list of all .csv files in dir_data\n",
    "dir_data_csv_files = sorted([f_.name for f_ in dir_data.glob('*.csv') if f_.is_file()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'filename' was provided, work with that .csv.\n",
    "# if 'filename' was not provided, review available .csv's.\n",
    "# if some .csv files are present, continue.  \n",
    "# Otherwise halt process and inform user.\n",
    "if filename == '':\n",
    "    try:\n",
    "        assert len(dir_data_csv_files) >= 1\n",
    "    except:\n",
    "        message_ = message_no_csv_files_found.format(\n",
    "            dir_data_posix = dir_data_posix)\n",
    "        print(message_)\n",
    "    #     assert\n",
    "        raise\n",
    "# elif filename != '':\n",
    "    \n",
    "# string version of list of all csv files\n",
    "dir_data_csv_files_str = ', '.join(dir_data_csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locate LCD .CSV file(s) 'files_lcd_input'\n",
    "This script is intended to be executed from a terminal command line.  The LCD input file(s) are expected to be saved in the same directory that the command line is executed in.  The file name(s) are expected to match the pattern associated with multiple LCD file versions in 'patterns_lcd_input_files' (two versions currently).  However, if a file(s) with this pattern is not identifed, do NOT attempt to use any non-matching .CSV file in the same directory.  Inform user that no matching file was found and no files will be opened or created.\n",
    "\n",
    "The benefits of this approach are:\n",
    "1. code will not mistakenly use non-LCD files\n",
    "2. User can be sloppy (or organized) with their LCD file storage.  New source files and output files can simply be accumulated in the same folder with no data loss.\n",
    "3. Simple command line requires no mandatory input, only optional frequency and parameter setting inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which version of LCD files are avaialble and which are the most recent?\n",
    "1. find all files that match v1 or v2 naming\n",
    "2. find the most recent file\n",
    "3. Determine if most recent file is v1 or v2 format 'lcd_version'\n",
    "4. see if there is more than one file with the same station ID\n",
    "5. create list 'files_lcd' with one or more lcd files of same station id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [WindowsPath('C:/Users/user/OneDrive/python_envs/noaa-weather-hourly-cli/dev/data/3876540.csv'),\n",
       "  WindowsPath('C:/Users/user/OneDrive/python_envs/noaa-weather-hourly-cli/dev/data/3875753.csv')],\n",
       " 2: []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. find all files that match v1 or v2 naming and sort by last modified date descending\n",
    "# create 'version_files' dictionary with LCD version number as key and list of matching \n",
    "# files as values\n",
    "version_files = {v_ : find_files_re_pattern_sorted_last_modified(dir_data, pattern_) for\n",
    "                 v_, pattern_ in version_pattern_lcd_input.items()}\n",
    "version_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if no files were found?  \n",
    "# return message and halt process\n",
    "# which files matched lcd patterns, regardless of version or date?\n",
    "# files_pattern_match = [x for xs in version_files.values() for x in xs]\n",
    "files_pattern_match = [x for xs in version_files.values() for x in xs]\n",
    "try:\n",
    "    assert len(files_pattern_match) >= 1\n",
    "except:\n",
    "    message_ = message_no_lcd_files_found.format(dir_data_posix = dir_data_posix,\n",
    "                                 patterns_lcd_examples_str = patterns_lcd_examples_str,\n",
    "                                dir_data_csv_files_str = dir_data_csv_files_str)\n",
    "    print(message_)\n",
    "#     assert\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: WindowsPath('C:/Users/user/OneDrive/python_envs/noaa-weather-hourly-cli/dev/data/3876540.csv'),\n",
       " 2: None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find most recently modified file by lcd version\n",
    "version_file_last_modified = {version_ : files_[0] if len(files_) > 0 else\n",
    "                              None for version_, files_ in version_files.items()}\n",
    "version_file_last_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. find the most recent file\n",
    "file_last_modified = sorted([(f, f.stat().st_mtime) for\n",
    "                  f in version_file_last_modified.values() if f != None],\n",
    "           key=lambda x: x[1], reverse=True)[0][0]\n",
    "# 3. Determine if most recent file is v1 or v2 format 'lcd_version'\n",
    "# versions start with '1' so need to add 1 to zero-indexed list\n",
    "lcd_version = list(version_file_last_modified.values())\\\n",
    "                            .index(file_last_modified) + 1\n",
    "# file_last_modified, lcd_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we have the right version\n",
    "assert file_last_modified in version_files[lcd_version]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group LCD .CSV input file(s) as 'files_lcd_input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. see if there is more than one file that has the same station ID\n",
    "# as found in 'file_last_modified'\n",
    "# This requires extraction of a unique identifier in LCD file name that is common to\n",
    "# other LCD files for same location (but probably different dates).  \n",
    "\n",
    "# Note that only the LCD v2 files need to be grouped.  LCD v1 files are \n",
    "# delivered with multi-year date ranges (if requested) while LCD v2\n",
    "# files are for discrete calendar years (or less), for example 'LCD_USW00014939_2020.csv'.  \n",
    "\n",
    "# Grouping LCD v1 files could be implemented, but this would require cooperation\n",
    "# from the user in terms of renaming the LCD v1 files in a specific format.\n",
    "# LCD v1 files are delivered with the same name ('3876540.csv') regardless\n",
    "# of date range of data in file.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_lcd_input - empty list to hold final, qualified selection of LCD input files\n",
    "files_lcd_input = []\n",
    "# different treatment for v2 LCD files\n",
    "if lcd_version == 2:\n",
    "# extract id_file_lcd2 as the blob of characters between first and second '_'\n",
    "# reference 'LCD_USW00014939_2023.csv'\n",
    "    id_file_lcd2 = file_last_modified.name.split('_')[1]\n",
    "#     which files contain id for the current lcd_version?\n",
    "    files_ = [file_ for file_ in version_files[lcd_version] if id_file_lcd2 in file_.name]\n",
    "    files_lcd_input.extend(files_)\n",
    "#     print('v2')\n",
    "else:\n",
    "    files_lcd_input.append(file_last_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string version of filenames from files_lcd_input as vertical list\n",
    "files_lcd_input_names_str = \"\\n\".join([f_.name for f_ in files_lcd_input])\n",
    "# files_lcd_input_names_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which columns are present by file in files_lcd_input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read only headers of each file in files_lcd_input\n",
    "files_columns = {}\n",
    "for file_ in files_lcd_input:\n",
    "    try:\n",
    "#         this is 30x faster than pd.read_csv(file_, index_col=0, nrows=0).columns.tolist()\n",
    "        with open(file_, 'r') as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            fieldnames = reader.fieldnames\n",
    "        files_columns[file_] = sorted(fieldnames)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create files_usecols containing validated files\n",
    "and columns to be used\n",
    "_validation for each file:_\n",
    "* is their a 'DATE' column?\n",
    "* is at least one of the `cols_data` columns available?\n",
    "* keep only columns found in `cols_noaa_processed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is 'DATE' available for every file in files_lcd_input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only files that have a 'DATE' column - otherwise where is this data supposed to go?\n",
    "files_usecols = {file_ : cols_ for file_, cols_ in files_columns.items()\n",
    "                 if 'DATE' in cols_}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep only files that have at least one cols_data column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_usecols = {file_ : cols_ for file_, cols_ in files_usecols.items()\n",
    "                 if len(set(cols_).intersection(set(cols_data))) >=1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce files_usecols to only columns used in this process\n",
    "files_usecols = {file_ : sorted(set(cols_noaa_processed).intersection(set(cols_))) for\n",
    "                 file_, cols_ in files_usecols.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create df from files_usecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyPressureChange</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlyStationPressure</th>\n",
       "      <th>HourlyVisibility</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindDirection</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>9.94</td>\n",
       "      <td>24.0</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.80</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.80</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 02:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.81</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.09</td>\n",
       "      <td>10.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 03:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.80</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 20:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>30.08</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 21:00:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.37</td>\n",
       "      <td>9.94</td>\n",
       "      <td>31.0</td>\n",
       "      <td>320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 21:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>30.09</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 22:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>30.11</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330</td>\n",
       "      <td>24.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-31 23:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>30.13</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51667 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         STATION HourlyAltimeterSetting  \\\n",
       "DATE                                                      \n",
       "2020-01-01 00:00:00  72530094846                    NaN   \n",
       "2020-01-01 00:51:00  72530094846                  29.80   \n",
       "2020-01-01 01:51:00  72530094846                  29.80   \n",
       "2020-01-01 02:51:00  72530094846                  29.81   \n",
       "2020-01-01 03:51:00  72530094846                  29.80   \n",
       "...                          ...                    ...   \n",
       "2023-12-31 20:51:00  72530094846                  30.08   \n",
       "2023-12-31 21:00:00  72530094846                    NaN   \n",
       "2023-12-31 21:51:00  72530094846                  30.09   \n",
       "2023-12-31 22:51:00  72530094846                  30.11   \n",
       "2023-12-31 23:51:00  72530094846                  30.13   \n",
       "\n",
       "                    HourlyDewPointTemperature HourlyDryBulbTemperature  \\\n",
       "DATE                                                                     \n",
       "2020-01-01 00:00:00                        21                       25   \n",
       "2020-01-01 00:51:00                        20                       24   \n",
       "2020-01-01 01:51:00                        19                       23   \n",
       "2020-01-01 02:51:00                        19                       22   \n",
       "2020-01-01 03:51:00                        19                       21   \n",
       "...                                       ...                      ...   \n",
       "2023-12-31 20:51:00                        27                       33   \n",
       "2023-12-31 21:00:00                        27                       33   \n",
       "2023-12-31 21:51:00                        27                       33   \n",
       "2023-12-31 22:51:00                        27                       33   \n",
       "2023-12-31 23:51:00                        27                       32   \n",
       "\n",
       "                    HourlyPrecipitation  HourlyPressureChange  \\\n",
       "DATE                                                            \n",
       "2020-01-01 00:00:00                 NaN                   NaN   \n",
       "2020-01-01 00:51:00                0.00                   NaN   \n",
       "2020-01-01 01:51:00                0.00                   NaN   \n",
       "2020-01-01 02:51:00                0.00                 -0.01   \n",
       "2020-01-01 03:51:00                0.00                   NaN   \n",
       "...                                 ...                   ...   \n",
       "2023-12-31 20:51:00                   T                 -0.06   \n",
       "2023-12-31 21:00:00                 NaN                 -0.06   \n",
       "2023-12-31 21:51:00                 NaN                   NaN   \n",
       "2023-12-31 22:51:00                 NaN                   NaN   \n",
       "2023-12-31 23:51:00                 NaN                 -0.05   \n",
       "\n",
       "                     HourlyRelativeHumidity HourlyStationPressure  \\\n",
       "DATE                                                                \n",
       "2020-01-01 00:00:00                    85.0                 29.10   \n",
       "2020-01-01 00:51:00                    84.0                 29.08   \n",
       "2020-01-01 01:51:00                    85.0                 29.08   \n",
       "2020-01-01 02:51:00                    89.0                 29.09   \n",
       "2020-01-01 03:51:00                    92.0                 29.08   \n",
       "...                                     ...                   ...   \n",
       "2023-12-31 20:51:00                    78.0                   NaN   \n",
       "2023-12-31 21:00:00                    78.0                 29.37   \n",
       "2023-12-31 21:51:00                    78.0                   NaN   \n",
       "2023-12-31 22:51:00                    78.0                   NaN   \n",
       "2023-12-31 23:51:00                    82.0                   NaN   \n",
       "\n",
       "                    HourlyVisibility  HourlyWetBulbTemperature  \\\n",
       "DATE                                                             \n",
       "2020-01-01 00:00:00             9.94                      24.0   \n",
       "2020-01-01 00:51:00            10.00                      23.0   \n",
       "2020-01-01 01:51:00            10.00                      22.0   \n",
       "2020-01-01 02:51:00            10.00                      21.0   \n",
       "2020-01-01 03:51:00            10.00                      20.0   \n",
       "...                              ...                       ...   \n",
       "2023-12-31 20:51:00            10.00                       NaN   \n",
       "2023-12-31 21:00:00             9.94                      31.0   \n",
       "2023-12-31 21:51:00            10.00                       NaN   \n",
       "2023-12-31 22:51:00            10.00                       NaN   \n",
       "2023-12-31 23:51:00            10.00                       NaN   \n",
       "\n",
       "                    HourlyWindDirection  HourlyWindGustSpeed  HourlyWindSpeed  \\\n",
       "DATE                                                                            \n",
       "2020-01-01 00:00:00                 270                  NaN              8.0   \n",
       "2020-01-01 00:51:00                 270                  NaN              8.0   \n",
       "2020-01-01 01:51:00                 260                  NaN              6.0   \n",
       "2020-01-01 02:51:00                 220                  NaN              5.0   \n",
       "2020-01-01 03:51:00                 230                  NaN              6.0   \n",
       "...                                 ...                  ...              ...   \n",
       "2023-12-31 20:51:00                 320                 24.0             16.0   \n",
       "2023-12-31 21:00:00                 320                  NaN             16.0   \n",
       "2023-12-31 21:51:00                 330                 22.0             13.0   \n",
       "2023-12-31 22:51:00                 330                 24.0             16.0   \n",
       "2023-12-31 23:51:00                 330                  NaN             13.0   \n",
       "\n",
       "                     Sunrise  Sunset  \n",
       "DATE                                  \n",
       "2020-01-01 00:00:00      NaN     NaN  \n",
       "2020-01-01 00:51:00      NaN     NaN  \n",
       "2020-01-01 01:51:00      NaN     NaN  \n",
       "2020-01-01 02:51:00      NaN     NaN  \n",
       "2020-01-01 03:51:00      NaN     NaN  \n",
       "...                      ...     ...  \n",
       "2023-12-31 20:51:00      NaN     NaN  \n",
       "2023-12-31 21:00:00      NaN     NaN  \n",
       "2023-12-31 21:51:00      NaN     NaN  \n",
       "2023-12-31 22:51:00      NaN     NaN  \n",
       "2023-12-31 23:51:00      NaN     NaN  \n",
       "\n",
       "[51667 rows x 15 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat((pd.read_csv(f_, usecols=cols_, parse_dates=['DATE'],\n",
    "                            index_col='DATE', low_memory=False) for\n",
    "                f_, cols_ in files_usecols.items()), axis=0)\\\n",
    "                .reset_index().drop_duplicates()\n",
    "df = df.set_index('DATE', drop=True).sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify columns expected to be numeric & force numeric conversion \n",
    "cols_numeric_stats = df.columns.difference(cols_sunrise_sunset + cols_date_station)\n",
    "for col_ in cols_numeric_stats:\n",
    "# for col_ in df.columns:\n",
    "    df[col_] = pd.to_numeric(df[col_], errors='coerce')\n",
    "    try:\n",
    "        df[col_] = df[col_].astype(float)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the count of raw timestamps prior to processing\n",
    "n_records_raw = df.shape[0]\n",
    "# track statistics by column prior to processing, omit 'Sunrise' & 'Sunset' from stats\n",
    "cols_sunrise_sunset = df.columns.intersection(['Sunrise', 'Sunset']).tolist()\n",
    "df_stats_pre = df.loc[:, df.columns.difference(cols_sunrise_sunset + cols_date_station)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51667, 15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df[cols_use].copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>HourlyAltimeterSetting</th>\n",
       "      <th>HourlyDewPointTemperature</th>\n",
       "      <th>HourlyDryBulbTemperature</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyPressureChange</th>\n",
       "      <th>HourlyRelativeHumidity</th>\n",
       "      <th>HourlyStationPressure</th>\n",
       "      <th>HourlyVisibility</th>\n",
       "      <th>HourlyWetBulbTemperature</th>\n",
       "      <th>HourlyWindDirection</th>\n",
       "      <th>HourlyWindGustSpeed</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "      <th>Sunrise</th>\n",
       "      <th>Sunset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>9.94</td>\n",
       "      <td>24.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.80</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>23.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.80</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 02:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.81</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>89.0</td>\n",
       "      <td>29.09</td>\n",
       "      <td>10.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 03:51:00</th>\n",
       "      <td>72530094846</td>\n",
       "      <td>29.80</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         STATION  HourlyAltimeterSetting  \\\n",
       "DATE                                                       \n",
       "2020-01-01 00:00:00  72530094846                     NaN   \n",
       "2020-01-01 00:51:00  72530094846                   29.80   \n",
       "2020-01-01 01:51:00  72530094846                   29.80   \n",
       "2020-01-01 02:51:00  72530094846                   29.81   \n",
       "2020-01-01 03:51:00  72530094846                   29.80   \n",
       "\n",
       "                     HourlyDewPointTemperature  HourlyDryBulbTemperature  \\\n",
       "DATE                                                                       \n",
       "2020-01-01 00:00:00                       21.0                      25.0   \n",
       "2020-01-01 00:51:00                       20.0                      24.0   \n",
       "2020-01-01 01:51:00                       19.0                      23.0   \n",
       "2020-01-01 02:51:00                       19.0                      22.0   \n",
       "2020-01-01 03:51:00                       19.0                      21.0   \n",
       "\n",
       "                     HourlyPrecipitation  HourlyPressureChange  \\\n",
       "DATE                                                             \n",
       "2020-01-01 00:00:00                  NaN                   NaN   \n",
       "2020-01-01 00:51:00                  0.0                   NaN   \n",
       "2020-01-01 01:51:00                  0.0                   NaN   \n",
       "2020-01-01 02:51:00                  0.0                 -0.01   \n",
       "2020-01-01 03:51:00                  0.0                   NaN   \n",
       "\n",
       "                     HourlyRelativeHumidity  HourlyStationPressure  \\\n",
       "DATE                                                                 \n",
       "2020-01-01 00:00:00                    85.0                  29.10   \n",
       "2020-01-01 00:51:00                    84.0                  29.08   \n",
       "2020-01-01 01:51:00                    85.0                  29.08   \n",
       "2020-01-01 02:51:00                    89.0                  29.09   \n",
       "2020-01-01 03:51:00                    92.0                  29.08   \n",
       "\n",
       "                     HourlyVisibility  HourlyWetBulbTemperature  \\\n",
       "DATE                                                              \n",
       "2020-01-01 00:00:00              9.94                      24.0   \n",
       "2020-01-01 00:51:00             10.00                      23.0   \n",
       "2020-01-01 01:51:00             10.00                      22.0   \n",
       "2020-01-01 02:51:00             10.00                      21.0   \n",
       "2020-01-01 03:51:00             10.00                      20.0   \n",
       "\n",
       "                     HourlyWindDirection  HourlyWindGustSpeed  \\\n",
       "DATE                                                            \n",
       "2020-01-01 00:00:00                270.0                  NaN   \n",
       "2020-01-01 00:51:00                270.0                  NaN   \n",
       "2020-01-01 01:51:00                260.0                  NaN   \n",
       "2020-01-01 02:51:00                220.0                  NaN   \n",
       "2020-01-01 03:51:00                230.0                  NaN   \n",
       "\n",
       "                     HourlyWindSpeed  Sunrise  Sunset  \n",
       "DATE                                                   \n",
       "2020-01-01 00:00:00              8.0      NaN     NaN  \n",
       "2020-01-01 00:51:00              8.0      NaN     NaN  \n",
       "2020-01-01 01:51:00              6.0      NaN     NaN  \n",
       "2020-01-01 02:51:00              5.0      NaN     NaN  \n",
       "2020-01-01 03:51:00              6.0      NaN     NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Display Weather Station Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('72530094846', '94846')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1 & v2\n",
    "# identify WBAN station\n",
    "station_lcd = str(df['STATION'].value_counts().index[0])\n",
    "station_wban = station_lcd[6:]  #important - this is index for the isd-history table\n",
    "station_call = station_lcd[-4:] #needed for non-USA locations with 99999 WBAN\n",
    "station_lcd, station_wban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'STATION', 'REPORT_TYPE', 'SOURCE' columns - not needed anymore\n",
    "df.drop(columns=['STATION', 'REPORT_TYPE', 'SOURCE'],\n",
    "        inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open 'isd-history.csv' containing Station details\n",
    "This is location identification information.  source:  https://www.ncei.noaa.gov/pub/data/noaa/isd-history.txt.  Parsed by 'ISD History Station Table.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/user/OneDrive/python_envs/noaa-weather-hourly-cli/dev/data')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_data_pkg = dir_cwd.parent / 'noaa_weather_hourly/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "isd_history_available = False\n",
    "file_isd_history = find_latest_file(dir_data, pattern_isd_history_file)\n",
    "# file_isd_history = find_latest_file(dir_data_pkg, pattern_isd_history_file)\n",
    "if file_isd_history.is_file():\n",
    "    isd_history_available = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create df_isd_history for Station Detail lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>CALL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBAN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63885</th>\n",
       "      <td>720381</td>\n",
       "      <td>JACK EDWARDS AIRPORT</td>\n",
       "      <td>US</td>\n",
       "      <td>AL</td>\n",
       "      <td>KJKA</td>\n",
       "      <td>+30.291</td>\n",
       "      <td>-087.672</td>\n",
       "      <td>+0004.9</td>\n",
       "      <td>2006-05-01</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96408</th>\n",
       "      <td>999999</td>\n",
       "      <td>DENALI 27 N</td>\n",
       "      <td>US</td>\n",
       "      <td>AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+63.452</td>\n",
       "      <td>-150.875</td>\n",
       "      <td>+0678.2</td>\n",
       "      <td>2015-08-19</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>717190</td>\n",
       "      <td>MISCOU ISLAND (AUT)</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CWMI</td>\n",
       "      <td>+48.017</td>\n",
       "      <td>-064.500</td>\n",
       "      <td>+0004.0</td>\n",
       "      <td>1977-07-01</td>\n",
       "      <td>2024-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>726427</td>\n",
       "      <td>RICHARD I BONG</td>\n",
       "      <td>US</td>\n",
       "      <td>WI</td>\n",
       "      <td>KSUW</td>\n",
       "      <td>+46.683</td>\n",
       "      <td>-092.100</td>\n",
       "      <td>+0205.0</td>\n",
       "      <td>1999-01-14</td>\n",
       "      <td>2005-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>842480</td>\n",
       "      <td>GENERAL MANUEL SERRANO</td>\n",
       "      <td>EC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SEMH</td>\n",
       "      <td>-03.269</td>\n",
       "      <td>-079.962</td>\n",
       "      <td>+0003.4</td>\n",
       "      <td>1977-10-01</td>\n",
       "      <td>1997-02-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         USAF            STATION NAME CTRY   ST  CALL      LAT       LON  \\\n",
       "WBAN                                                                       \n",
       "63885  720381    JACK EDWARDS AIRPORT   US   AL  KJKA  +30.291  -087.672   \n",
       "96408  999999             DENALI 27 N   US   AK   NaN  +63.452  -150.875   \n",
       "99999  717190     MISCOU ISLAND (AUT)   CA  NaN  CWMI  +48.017  -064.500   \n",
       "99999  726427          RICHARD I BONG   US   WI  KSUW  +46.683  -092.100   \n",
       "99999  842480  GENERAL MANUEL SERRANO   EC  NaN  SEMH  -03.269  -079.962   \n",
       "\n",
       "       ELEV(M)       BEGIN         END  \n",
       "WBAN                                    \n",
       "63885  +0004.9  2006-05-01  2024-12-31  \n",
       "96408  +0678.2  2015-08-19  2024-12-31  \n",
       "99999  +0004.0  1977-07-01  2024-12-31  \n",
       "99999  +0205.0  1999-01-14  2005-12-31  \n",
       "99999  +0003.4  1977-10-01  1997-02-03  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isd_history = pd.read_csv(file_isd_history, index_col='WBAN',\n",
    "                     dtype={'WBAN': object}).sort_values(\n",
    "                    by=['USAF', 'BEGIN'], ascending=[True, False])\n",
    "# ensure WBAN index is a 5-character string\n",
    "df_isd_history.index.index = df_isd_history.index.str.zfill(5)\n",
    "df_isd_history.sample(5).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_wban in df_isd_history.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BOGUS NORWAY', 'JAN MAYEN(NOR-NAVY)', 'SORSTOKKEN', ...,\n",
       "       'IONIA COUNTY AIRPORT', 'DEMOPOLIS MUNICIPAL AIRPORT',\n",
       "       'BRANSON WEST MUNICIPAL EMERSO'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isd_history['STATION NAME'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11611 entries, 99999 to 00451\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   USAF          11611 non-null  object\n",
      " 1   STATION NAME  11609 non-null  object\n",
      " 2   CTRY          11594 non-null  object\n",
      " 3   ST            5442 non-null   object\n",
      " 4   CALL          10661 non-null  object\n",
      " 5   LAT           11583 non-null  object\n",
      " 6   LON           11582 non-null  object\n",
      " 7   ELEV(M)       11556 non-null  object\n",
      " 8   BEGIN         11609 non-null  object\n",
      " 9   END           11611 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_isd_history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>ST</th>\n",
       "      <th>CALL</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBAN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [USAF, STATION NAME, CTRY, ST, CALL, LAT, LON, ELEV(M), BEGIN, END]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_isd_history.loc[df_isd_history['CALL']==station_call]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the station WBAN listed in df_isd_history?\n",
    "station_details_available_wban = station_wban in df_isd_history.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the station CALL listed in df_isd_history?\n",
    "station_details_available_call = station_call in df_isd_history['CALL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([station_details_available_wban, station_details_available_call])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if station_details_available_wban:\n",
    "    station_details = dict(df_isd_history.loc[station_wban].reset_index()\\\n",
    "                       .sort_values('END', ascending=False).iloc[0])\n",
    "elif station_details_available_call:\n",
    "    station_details = dict(df_isd_history.loc[\n",
    "                        df_isd_history['CALL'] == station_call]\\\n",
    "                       .reset_index().sort_values('END',\n",
    "                          ascending=False).iloc[0])\n",
    "else:\n",
    "    station_details = {col_ : 'Unknown' for col_ in df_isd_history.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if station_details['LAT'] != 'Unknown':\n",
    "     # add url to google maps search of lat, lon values to station_details\n",
    "    google_maps_lat_lon_url = \"\"\"https://maps.google.com/?q={lat},{long}\"\"\"\n",
    "    google_maps_url = google_maps_lat_lon_url.format(lat = station_details['LAT'],\n",
    "                                                    long = station_details['LON'])\n",
    "    station_details['GOOGLE MAP'] = google_maps_url\n",
    "\n",
    "# delete df_isd_history - no longer needed\n",
    "del df_isd_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WBAN': '94846',\n",
       " 'USAF': '725300',\n",
       " 'STATION NAME': \"CHICAGO O\\\\'HARE INTERNATIONAL\",\n",
       " 'CTRY': 'US',\n",
       " 'ST': 'IL',\n",
       " 'CALL': 'KORD',\n",
       " 'LAT': '+41.960',\n",
       " 'LON': '-087.932',\n",
       " 'ELEV(M)': '+0204.8',\n",
       " 'BEGIN': '1946-10-01',\n",
       " 'END': '2024-12-31',\n",
       " 'GOOGLE MAP': 'https://maps.google.com/?q=+41.960,-087.932'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2020-01-01', '2023-12-31')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#     create timestamps for consolidated table df\n",
    "start_dt = df.index[0]\n",
    "end_dt = df.index[-1]\n",
    "start_str = start_dt.strftime('%Y-%m-%d')\n",
    "end_str = end_dt.strftime('%Y-%m-%d')\n",
    "start_str, end_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify hourly timestamps where the LCD source reported no observations\n",
    "# This will be added as a boolean column later\n",
    "idx_hours_no_source_data = pd.date_range(start_dt, end_dt, freq='H')\\\n",
    "                            .difference(df.index.round('H'))\n",
    "# how many hours of the curent time range have no observations?\n",
    "n_hours_no_source_data = len(idx_hours_no_source_data)\n",
    "# idx_hours_no_source_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolve duplicate datetime index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51594, 14)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if a single timestamp appears more than once, average available values\n",
    "# to return a single value and single timestamp (ignoring \n",
    "# NaN values of course)\n",
    "df = df.groupby(level=0).mean()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Sunrise and Sunset by date in to dictionaries\n",
    "to be applied to df_out towards end of script.\n",
    "Drop Sunrise and Sunset columns after extraction here.\n",
    "The source data provides only one unique sunrise/set value per day and\n",
    "the rest of the day's values are NaN.  \n",
    "\n",
    "V1 files placed sunrise/set values at the 23:59:00 timestamp.  Additional steps are taken to ensure v1 files assign sunrise/set times to a date (ie., Timestamp('2022-01-01 00:00:00'): Timestamp('2022-01-01 17:09:00') and NOT Timestamp('2022-01-01 23:59:00'): Timestamp('2022-01-01 17:09:00')), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create date_sunrise/sunset dictionaries with dates as keys and \n",
    "# # timestamp values for time to be added back in to resampled df\n",
    "temp_sunrise = df['Sunrise'].dropna()\n",
    "temp_sunrise.index = temp_sunrise.index.floor('D')\n",
    "date_sunrise = datetime_from_HHMM(temp_sunrise).to_dict()\n",
    "del temp_sunrise\n",
    "\n",
    "temp_sunset = df['Sunset'].dropna()\n",
    "temp_sunset.index = temp_sunset.index.floor('D')\n",
    "date_sunset = datetime_from_HHMM(temp_sunset).to_dict()\n",
    "del temp_sunset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop sunrise/sunset columns as their information is now \n",
    "# contained in the date_sunrise/sunset dictionaries\n",
    "df.drop(columns=cols_sunrise_sunset, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### are there timestamps that have a high count of null values?\n",
    "In v1 LCD files the '23:59:00' timestamp is suspect and appears to only be a placeholder\n",
    "for posting sunrise/sunset times.  Important that this step be done after\n",
    "forward filling sunrise/sunset values. \n",
    "V2 LCD files do not seem to have the '23:59:00' timestamp issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_records_hourly_approx = int(df.shape[0]/(24))\n",
    "# n_max_null = pct_null_timestamp_max * n_records_hourly_approx\n",
    "n_max_null = int(pct_null_timestamp_max * df.shape[0])\n",
    "n_max_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.loc[:, df.columns.difference(cols_sunrise_sunset)]\n",
    "df_nan_ts = temp.groupby(temp.index.time).apply(lambda x: x.isna().sum()\\\n",
    "                            .gt(n_max_null)).all(axis=1)\n",
    "times_nan = df_nan_ts.loc[df_nan_ts].index.tolist()\n",
    "del temp\n",
    "del df_nan_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove records for timestamps with a high percentage of Null values.\n",
    "# note that the '23:59:00' timestamp is suspect and appears to only be a placeholder\n",
    "# for posting sunrise/sunset times.  Important that this step be done after\n",
    "# forward filling sunrise/sunset values.\n",
    "filter_nan_times = pd.Series(df.index.time).isin(times_nan).values\n",
    "df = df.loc[~filter_nan_times]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = df.between_time('23:01:00', '00:59:00').select_dtypes(include=[int, float])\n",
    "# test.groupby(test.index.time).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_development:\n",
    "    df.groupby(df.index.time).count().max(axis=1).sort_index().plot(figsize=(11,3),\n",
    "   title='Count of Maximum Non-Null Readings per \"time\" Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[filter_nan_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Check what percentage of data has null data and print to screen\n",
    "df_pct_null_data = pd.DataFrame({'Percent N/A': df.isnull().sum().divide(len(df)).round(3)})\n",
    "df_pct_null_data_pre_formatted = df_pct_null_data['Percent N/A']\\\n",
    "                            .apply(lambda n: '{:,.1%}'.format(n))\n",
    "# remove 'Hourly' prefix for display only\n",
    "col_rename_remove_hourly = {col_ : col_.replace('Hourly', '') for\n",
    "                            col_ in df_pct_null_data_pre_formatted.index}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Station Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude station lifetime history dates - could cause confusion\n",
    "station_details_exclude = ['BEGIN', 'END']\n",
    "station_details_display = {k_ : v_ for k_, v_ in station_details.items() if\n",
    "                           k_ not in station_details_exclude}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------')\n",
    "print('------ ISD Weather Station Properties ------')\n",
    "print('--------------------------------------------')\n",
    "for k_, v_ in station_details_display.items():\n",
    "    print(\"{:<15} {:<10}\".format(k_, v_))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# message_pct_null_data = f\"\"\"Percent Missing Values by Column for LCD source file '{file_lcd_input.name}' for USAF station {station_usaf} at '{station_details['STATION NAME']}' from {start_str} to {end_str}.\"\"\"\n",
    "# message_pct_null_data = \"\"\"Percent Missing Values by Column for LCD source file(s):\n",
    "# {files_lcd_input_names_str}\\n\\nFor USAF station {station_usaf} at '{station_name}'\n",
    "# from {start_str} to {end_str}.\"\"\"\n",
    "message_pct_null_data = \"\"\"Percent Missing Values by Column from {start_str} to {end_str} for LCD source file(s):\\n\n",
    "{files_lcd_input_names_str}\"\"\"\n",
    "message_ = message_pct_null_data.format(files_lcd_input_names_str = files_lcd_input_names_str,\n",
    "                            station_usaf = station_details['USAF'],\n",
    "                            station_name = station_details['STATION NAME'],\n",
    "                            start_str = start_str,\n",
    "                            end_str = end_str)\n",
    "\n",
    "print(message_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--------------------------------------------------------------')\n",
    "print('------ Percent Null Values by Column Before Processing -------')\n",
    "print('--------------------------------------------------------------')\n",
    "display(df_pct_null_data_pre_formatted.rename(index=col_rename_remove_hourly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dfs = {}\n",
    "# individually resample each column on an hourly frequency.\n",
    "# This will produce series\n",
    "# with perfect, complete datetime indexes.  However, it is quite\n",
    "# possible that NaN values will remain (ie. a contiguous 3-hour\n",
    "# period of NaN values).  Remaining NaN values will\n",
    "# be resolved through interpolation later in the script.\n",
    "# this method is used because NaN values can appear at different timestamps\n",
    "# in each column\n",
    "# at this point the df should contain only numeric data\n",
    "for col_ in df.columns:\n",
    "    print(col_)\n",
    "    dfs[col_] = df[col_].dropna().resample('H').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create df_out - the beginning of the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the resampled series from the previous step, remove any\n",
    "# duplicates and ensure the index is recognized as hourly frequency.\n",
    "# df_out = pd.concat(dfs, axis=1).drop_duplicates().asfreq('H')\n",
    "# important to enforce dtype 'float' as 'HourlyRelativeHumidity' and \n",
    "# other columns had a 'Float64' (capital 'F') that generated\n",
    "# errors in interpolation step.\n",
    "df_out = pd.concat(dfs, axis=1).drop_duplicates()\\\n",
    "                .asfreq('H').astype(float)\n",
    "del dfs\n",
    "del df\n",
    "df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolate Null Values\n",
    "According to the following parameters:\n",
    "Because observed weather data commonly contains gaps (ie., NaN or null values), noaa-weather-hourly will attempt to fill in any such gaps to ensure that in each record a value is present for all of the hourly timestamps. To do so, it will use time-based interpolation for gaps up to a default value of 24 hours long ('max_records_to_interpolate').  For example if the dry bulb temperature has a gap with neighboring observed values like (20, X, X, X, X, 25), noaa-weather-hourly will replace the missing values to give (20, 21, 22, 23, 24, 25).\n",
    "\n",
    "If a gap exists in the data that is larger than max_records_to_interpolate, NaN values will be left untouched and a complete datetime index will be preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.interpolate(method='time',\n",
    "            limit = max_records_to_interpolate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Frequency Resample\n",
    "If the freqstr is not 'H', resample.  If the input freqstr is higher than 'H', resample and interpolate, else resample using mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freqstr = '30T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_resample = False\n",
    "resample_interpolate = False\n",
    "#     what is the delta value of the input freqstr?\n",
    "freqstr_delta = pd.date_range(start_dt, periods=100,\n",
    "                           freq=freqstr).freq.delta\n",
    "# If the freqstr is not 'H', run the resample process\n",
    "if freqstr != 'H':\n",
    "    run_resample = True\n",
    "\n",
    "# If the input freqstr is higher frequency \n",
    "# than df_out, resample using interpolation\n",
    "resample_interpolate = freqstr_delta < df_out.index.freq.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_resample:\n",
    "#     resample via interpolation\n",
    "    if resample_interpolate:\n",
    "        df_out = df_out.resample(freqstr).interpolate()\n",
    "# or resample using mean\n",
    "    elif not resample_interpolate:\n",
    "        df_out = df_out.resample(freqstr).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre- Post-Processing Statistical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create general statistics on post-processed dataset for\n",
    "# comparison with pre-processed dataset to understand how/if \n",
    "# processing significantly altered series values\n",
    "df_stats_post = df_out[df_stats_pre.columns].describe()\n",
    "df_stats_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_comp = pd.concat([df_stats_pre.loc['mean'].T, df_stats_post.loc['mean'].T],\n",
    "                         axis=1, keys=['Source Mean', 'Processed Mean']).round(2)\n",
    "df_mean_comp['% Difference'] = df_mean_comp.pct_change(axis=1).iloc[:,-1]\\\n",
    "                                .fillna(0).round(4)\\\n",
    "                                .apply(lambda n: '{:,.2%}'.format(n))\n",
    "df_mean_comp.rename(index=col_rename_remove_hourly, inplace=True)\n",
    "df_mean_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO:  Overall pre- post- statistics check\n",
    "df_stats_pre.sub(df_stats_post).div(df_stats_pre).mean().mean()\n",
    "# df_stats_pre.pct_change(df_stats_post)\n",
    "# df_stats_pre.eq(df_stats_post).sum().sum()\n",
    "# df_stats_pre.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     Check what percentage of data has null data and print to screen\n",
    "df_pct_null_data_post = pd.DataFrame({'Percent N/A': df_out.isnull()\\\n",
    "                              .sum().divide(len(df_out)).round(4)})\n",
    "df_pct_null_data_post_formatted = df_pct_null_data_post['Percent N/A']\\\n",
    "                                .apply(lambda n: '{:,.2%}'.format(n))\n",
    "display(df_pct_null_data_post_formatted.rename(\n",
    "                index = col_rename_remove_hourly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_null_comp = pd.concat([df_pct_null_data_pre_formatted, \n",
    "                             df_pct_null_data_post_formatted], \n",
    "                            axis=1).rename(index=col_rename_remove_hourly)\n",
    "df_pct_null_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pct_null_comp.join(df_mean_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round df_out to 1 decimal place\n",
    "df_out = df_out.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Sunrise/Sunset timestamps to df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply date_sunrise/sunset to df_out index to create sunrise/sunset columns\n",
    "for col_, dict_ in zip(cols_sunrise_sunset, [date_sunrise, date_sunset]):\n",
    "    if len(dict_) > 1:\n",
    "        df_out[col_] = pd.DataFrame.from_dict(dict_, orient='index')\\\n",
    "                    .reindex(df_out.index).ffill().astype('datetime64[s]')\n",
    "    else:\n",
    "        df_out[col_] = pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_development:\n",
    "#     df_out[cols_sunrise_sunset].diff(axis=1).iloc[:,-1].dt.total_seconds().div(3600).plot()\n",
    "    df_out[cols_sunrise_sunset].diff(axis=1).iloc[:,-1]\\\n",
    "        .dt.seconds.div(3600).plot(\n",
    "        title = 'Duration of Daylight (hours)', figsize = (11,3), lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column to document hourly obervations where no source data was provided.\n",
    "df_out['No source data'] = df_out.index.isin(idx_hours_no_source_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No duplicate records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete and consistent timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### correct dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nan values only in columns permitted to have NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename Columns - remove 'hourly' from names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.rename(columns=col_rename_remove_hourly, errors='ignore',\n",
    "             inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Outputs to Disk\n",
    "* df_out\n",
    "* df_mean_comp\n",
    "* df_pct_null_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO-DO:\n",
    "Consolidated processing summary report as .txt file containing df_mean_comp, df_pct_null_comp, station_details, and other statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name export file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output file to current working directory (ie,\n",
    "# where command line command was entered)\n",
    "file_out_name = file_output_format.format(\n",
    "            STATION_NAME = slugify(station_details['STATION NAME']),\n",
    "            start_str = start_str,\n",
    "            end_str = end_str,\n",
    "            freqstr = freqstr)\n",
    "file_out = dir_cwd / file_out_name\n",
    "# what if file name is too long for current OS? - TO-DO\n",
    "# file_out.as_posix().__len__()\n",
    "file_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save df_out to csv as file_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv(file_out)\n",
    "assert file_out.is_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "NOAA_weather",
   "language": "python",
   "name": "noaa_weather"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
